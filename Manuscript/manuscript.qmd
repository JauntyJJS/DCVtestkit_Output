---
title: "*DCVtestkit*: a R package for linearity assessment and visualisation of multiple curves"

bibliography: bibliography.bib
csl: bioinfo.csl
format: docx

crossref:
  fig-title: Fig.
  fig-prefix: Fig.
  subref-labels: alpha A
  title-delim: .
---

```{r R packages}
#| echo: false
#| message: false

library(dplyr)
library(stringr)
library(here)
library(labelled)
library(gtsummary)
library(flextable)
library(webshot2)

```

## Manuscript Type

Application Note

# Abstract

## Summary

Linearity assessment plays a significant role in the validation of quantitative analytical laboratory procedures. In metabolomic and lipidomic workflows, a linear response in dilution series generated from pooled quality control samples is used to assess the quality of the measurement of molecules measured before further analysis. Most of the currently used software only allow the analyst to repetitively plot, view and analyse the dilution curves one at a time, a tedious and time-consuming process. In addition, summary statistics of dilution curves are limited to the Pearson Correlation Coefficient which is insufficient to fully understand the shape of the dilution curves. *DCVtestkit* aims to provide additional summary statistics for dilution curves, taken from previous publications but which are not implemented in the current software tools. It also helps to reduce the analyst's workload by analysing many dilution curves automatically, reporting the statistical results in Excel and recording the dilution plots in a pdf file. In addition, it can also create an interactive trellis displayed as a HTML folder for more exploratory analysis.

## Availability and implementation

*DCVtestkit* is available on GitHub <https://github.com/SLINGhub/DCVtestkit>. The documentation and tutorials can be accessed from <https://slinghub.github.io/DCVtestkit/>

## Supplementary information

Supplementary data are available at *Bioinformatics* online.

## Issue Section

Data and text mining

{{< pagebreak >}}

# Introduction

Linearity assessment, as summarised by @paulson1995, is a standard protocol to verify if an instrument or experimental method is in working condition, especially if the method is used to report quantitative results. It is applied in many fields in science such as calibration/dilution studies (@rodr√≠guez1993 and @sands2021) and assay development (@ross2003 and @hsieh2008). During analysis, curves are plotted individually with a Pearson Correlation Coefficient value for each measurement using general-purpose software like Excel.

However, as instrument or experimental method are becoming more high throughput, many measurements can be done at a short time. Having the analyst to individually plot numerous curves to check for linearity is time-consuming. Furthermore, @sonnergaard2006 warns that the Pearson Correlation Coefficient is not an effective standalone numeric parameter to estimate linearity. While researchers have created other metrics for linearity evaluation, these metrics are rarely implemented in most general-purpose software.

R package, *DCVtestkit* addresses these issues by assisting analysts, to plot curves from many experiments easily with additional metrics, other than the Pearson Correlation Coefficient, that better describe the curve's shape. It also provides an interactive viewer for analysts to group, filter and sort the plots, allowing them to look at problematic ones, such as saturated curves.

# Approach

Using the analysis of dilution curves in meatbolomic/lipidomic study as a running example, Supplementary Figure 1 depicts the workflow of *DCVtestkit*. The workflow starts with two tables: Transition Signal Data, containing transition signals (y-axis for dilution curve) for each sample and Dilution Annotation, containing dilution curve related information, such as concentration (x-axis for dilution curve) and dilution batches. Using a common column Sample Name, the two tables can be merged into one table (Dilution Table) via `create_dilution_table`.

Next, summary statistics are calculated via `summarise_dilution_table` for each dilution curve. Besides the Pearson Correlation Coefficient, one additional calculation is the Mandel's Fitting Test ($F_{stats}$ in @eq-mandel-test) from @andrade2013. A low $p$ value from the $F$ test gives sufficient evidence that a quadratic model fits better than a linear model, indicating the curve may not be linear.

$$
\begin{aligned}
&F_{stats} = \frac{(n-2) \ \mathrm S_{lin}^2 \ - \ (n-3) \ \mathrm S_{quad}^2}{\mathrm S_{quad}^2} \sim \ F(1,n-3)
\\
\\
&\text{where}
\\
&\mathrm S_{lin}^2 = \frac{1}{n-2} \sum_{i=1}^{n} ( y_{i,lin} - y_{i,true})^2 
\\
&\mathrm S_{quad}^2 = \frac{1}{n-3} \sum_{i=1}^{n} ( y_{i,quad} - y_{i,true})^2
\\ 
&y_{i,lin} \ \text{is the linear model predicted y-axis value.}
\\ 
&y_{i,quad} \ \text{is the quadratic model predicted y-axis value.}
\\ 
&y_{i,true} \ \text{is the true y-axis value.}
\\ 
&n \ \text{is the number of data points.}
\end{aligned}
$$ {#eq-mandel-test} Another one is Percent Residual Accuracy ($\%RA$ in @eq-pra) from @logue2018. Ranging from $-\infty$ to $100$, if the curve is linear, the value should be close to $100$.

$$
\begin{aligned}
&\%RA = \frac{100\%}{n} \sum_{i=1}^{n}\left(1 - \bigg| \frac{x_{i,true}-x_{i,lin}}{x_{i,true}} \bigg|\right)
\\
\\
&\text{where}
\\
&x_{i,true} \ \text{is the true x-axis value.}
\\ 
&x_{i,lin} \ \text{is the linear model predicted x-axis value.}
\\ 
&n \ \text{is the number of data points.}
\end{aligned}
$$ {#eq-pra}

The software also calculates the concavity of a fitted quadratic model to identify if the curve is dominantly non-linear at high (concavity $<0$) or low (concavity $>0$) concentrations.

Supplementary Figure 2 gives the summary statistics of three manually curated curves: A linear curve and curves with a plateau at higher concentrations (denoted as saturated curves) and lower concentrations (denoted as limit or detection or LOD curves) respectively. The corresponding Pearson Correlation Coefficient values (`r_corr`) are $\ge0.9$ ($0.99$, $0.95$ and $0.98$ respectively), even for the curves that are non-linear. However, both saturated and LOD curves give a much lower Mandel's Fitting Test $p$ values (`mandel_p_val`) ($1.66 * 10^{-4}$ and $2.56 * 10^{-3}$ respectively vs $0.38$). Likewise, the Percent Residual Accuracy values (`pra_linear`) are much lower in the saturated and LOD curves compared to the linear curve ($62.30$ and $74.69$ respectively vs $94.32$).

::: {#fig-overview layout="[[50,-50], [60,-40]]"}
![Curve Grouping Workflow](images/README-LinearEvaluation.png){#fig-linearity}

![Interactive Trellis Plots](images/README-TrellisOutput.png){#fig-visualisation}

*DCVtestkit*'s curve grouping workflow in @fig-linearity and interactive visualisation of curves in @fig-visualisation.
:::

`evaluate_linearity` is used to group the curves according to the workflows proposed in @fig-linearity. Workflow 1 uses the Pearson Correlation Coefficient and Percent Residual Accuracy to determine if the curve is linear (labelled as Good Linearity) or not (labelled as Poor Linearity). Workflow 2 goes one step further, using the Mandel's Fitting Test and the fitted quadratic model's concavity to check if the non-linear curve plateaus at low (labeled as limit of detection) or high (labelled as saturation) concentrations. Non-linear curves that do not follow these trends are labelled as Poor Linearity.

```{r Load Simulated Data Results}
#| echo: false
saturation_dilution_summary <-
  readRDS(file = here::here(
    "Quarto_Simulation",
    "saturation_dilution_summary.rds")
)

lod_dilution_summary <-
  readRDS(file = here::here(
    "Quarto_Simulation",
    "lod_dilution_summary.rds")
)

linear_dilution_summary <-
  readRDS(file = here::here(
    "Quarto_Simulation",
    "linear_dilution_summary.rds")
)
```

```{r Combine Simulated Data Results}
#| echo: false
saturation_dilution_summary <- saturation_dilution_summary |> 
  dplyr::mutate(curve_group = "Saturated")

lod_dilution_summary <- lod_dilution_summary |> 
  dplyr::mutate(curve_group = "Limit of Detection")

linear_dilution_summary <- linear_dilution_summary |> 
  dplyr::mutate(curve_group = "Linear")

combined_dilution_summary <-
  dplyr::bind_rows(
    saturation_dilution_summary,
    lod_dilution_summary,
    linear_dilution_summary
  ) 
```

```{r Data Wrangling for Simulation Results}
#| echo: false
combined_dilution_summary <- 
  combined_dilution_summary |> 
  dplyr::mutate(
    curve_group = factor(.data$curve_group,
                         levels = c("Linear",
                                    "Saturated",
                                    "Limit of Detection")),
    pearson_group = dplyr::case_when(
      .data$r_corr >= 0.8 ~ "more than or\nequal to 0.8",
      .data$r_corr < 0.8 ~ "less than 0.8",
    ),
    wf2_group = stringr::str_replace(
      string = .data$wf2_group,
      pattern = "LOD",
      replacement = "Limit of Detection"
    ),
    wf2_group = factor(.data$wf2_group,
                         levels = c("Good Linearity",
                                    "Saturation",
                                    "Limit of Detection",
                                    "Poor Linearity"))
  ) |> 
  labelled::set_variable_labels(
    ID = "Unique Curve Identifier",
    curve_group = "Simulated Curve Group",
    wf1_group = "Workflow 1 Grouping",
    wf2_group = "Workflow 2 Grouping",
    pearson_group = "Pearson Correlation\nCoefficient Grouping",
    r_corr = "Pearson Correlation\nCoefficient",
    pra_linear = "Percent Residual\nAccuracy",
    mandel_p_val = "Mandel's Test p Value",
    concavity = "Concavity Of Fitted Quadratic Model",
    r2_linear = "Coefficient Of Determination",
    r2_adj_linear = "Adjusted Coefficient Of Determination",
    mandel_stats = "Test statistics from Mandel's Test"
  )

```

```{r Simulation Results Table}
#| echo: false
#| output: false
simulation_results <- combined_dilution_summary |> 
  dplyr::select(c("curve_group", "wf2_group", 
                  "pearson_group"
                  # "r_corr", "pra_linear"
                  )
                ) |> 
  dplyr::relocate(c("pearson_group")) |> 
  gtsummary::tbl_summary(
    by = "curve_group",
    statistic = list(
      pearson_group ~ "{n}/{N} ({p}%)",
      wf2_group ~ "{n}/{N} ({p}%)"
    ),
    digits = list(
      wf2_group ~ c(0, 0, 1),
      pearson_group ~ c(0, 0, 1)
      #r_corr ~ c(2),
      #pra_linear ~ c(0)
      )
  ) |> 
  gtsummary::modify_header(
    gtsummary::all_stat_cols() ~ "**{level}**\nN = {n}"
    ) |> 
  gtsummary::modify_spanning_header(
    gtsummary::all_stat_cols() ~ "**Simulated Curve Type**"
    )
```

A benchmark workflow using only Pearson Correlation Coefficient value of $0.8$ is compared with Workflow 2 on simulated data sets of `r nrow(linear_dilution_summary)` linear curves (labelled as Linear), curves that plateau at low (labelled as Limit of Detection) high (labelled as Saturated) concentrations each. Supplementary Figure 3 showed that Workflow 2 better identifies the saturated and limit of detection curves than the benchmark workflow. While it identifies less linear curves correctly than the benchmark workflow, its score of `r inline_text(simulation_results, variable = wf2_group, level = "Good Linearity", column = "Linear")` is comparable. See <https://dcvtestkit-simulation.netlify.app> for report details. While the threshold values of Pearson Correlation Coefficient and Percent Residual Accuracy are based on the interpretation of @y.h.chan2003 and @logue2018, respectively, they remain subjective and arbitrary. Nevertheless, *DCVtestkit* allows optimization of these threshold values according to the analyst's determinants of linearity.

Although *DCVtestkit* can export the results in Excel or pdf, they may be too complex for meaningful interpretation. @fig-visualisation shows a HTML folder, exported by *DCVtestkit*, such that clicking on the `index.html` file inside the folder will open an interactive trellis plots that analysts can be grouped, filtered and sorted. This allows room for exploratory data analysis, such as identifying molecules with linearity issues or finding out the effects of changing the Pearson Correlation Coefficient threshold to another value. Such information is hard to achieve with the Excel and pdf files. An example of an interactive viewer created by *DCVtestkit* can be viewed at <https://dcvtestkit-interactive-example.netlify.app>

# Conclusion

To verify if an instrument or experimental method is reliable, it is important to check for linearity. However, there are few software that can to do efficiently at a high throughput setting. R package, *DCVtestkit*, rectifies this by plotting of many curves quickly by automation and reporting alternative statistics, other than the Pearson Correlation Coefficient, to better describe the shape of curves. It also provides an interactive trellis plot for exploratory data analysis. It is available on GitHub <https://github.com/SLINGhub/DCVtestkit> while the documentation and tutorials can be accessed from <https://slinghub.github.io/DCVtestkit>.

# Acknowledgements

These should be included at the end of the text and not in footnotes. Please ensure you acknowledge all sources of funding, see funding section below.

Details of all funding sources for the work in question should be given in a separate section entitled 'Funding'. This should appear before the 'Acknowledgements' section.

# Funding

The following rules should be followed:

-   The sentence should begin: 'This work was supported by ...' -
-   The full official funding agency name should be given, i.e. 'National Institutes of Health', not 'NIH' (full RIN-approved list of UK funding agencies)
-   Grant numbers should be given in brackets as follows: '\[grant number xxxx\]'
-   Multiple grant numbers should be separated by a comma as follows: '\[grant numbers xxxx, yyyy\]'
-   Agencies should be separated by a semi-colon (plus 'and' before the last funding agency)
-   Where individuals need to be specified for certain sources of funding the following text should be added after the relevant agency or grant number 'to \[author initials\]'.

An example is given here: 'This work was supported by the National Institutes of Health \[AA123456 to C.S., BB765432 to M.H.\]; and the Alcohol & Education Research Council \[hfygr667789\].'

Oxford Journals will deposit all NIH-funded articles in PubMed Central. See Depositing articles in repositories -- information for authors for details. Authors must ensure that manuscripts are clearly indicated as NIH-funded using the guidelines above.

# References
