---
title: "*lancer*: an R package for linearity assessment and visualisation of multiple curves"

bibliography: bibliography.bib
csl: bioinfo.csl
format: docx

crossref:
  fig-title: Fig.
  fig-prefix: Fig.
  subref-labels: alpha A
  title-delim: .
---

```{r R packages}
#| echo: false
#| message: false

library(dplyr)
library(stringr)
library(here)
library(labelled)
library(gtsummary)
library(flextable)
library(webshot2)

```

## Manuscript Type

Application Note

# Abstract

## Summary

Linearity assessment plays a significant role in the validation of instrumentation and experimental procedures. Linearity can be tested by applying several graphical and numerical approaches. Summary statistics of these curves are mostly limited to the Pearson Correlation Coefficient, which is insufficient to fully test the for linearity. In addition, spreadsheet software only allow the analyst to repetitively plot, view and analyse the linearity of curves one at a time, a tedious and time-consuming process. While plotting of many curves at once and calculation of additional summary statistics for assessing linearity of curves can be done using R, implementing this from scratch can be arduous task for the analyst. As such, we created the R package *lancer* so that curves can be analysed efficiently with a few functions. To our knowledge, this is currently not implemented in other software or programming languages. *lancer* furthermore reports the statistical results in tables/spreadsheets and records the plots in a pdf file. In addition, *lancer* can also create interactive trellis plots, displayed as a HTML folder, for exploratory analysis, helping analysts when dealing with large datasets.

## Availability and implementation

*lancer* is available on GitHub <https://github.com/SLINGhub/lancer>. The documentation and tutorials can be accessed from <https://slinghub.github.io/lancer/>

## Supplementary information

Supplementary data are available at *Bioinformatics* online.

## Issue Section

Data and text mining

{{< pagebreak >}}

# Introduction

Linearity assessment is an important performance test of an analytical instrument or method when a linear response is assumed. It is applied in many fields in analytical sciences, such as assay development (@ross2003 and @hsieh2008), calibration/dilution studies (@rodríguez1993 and @sands2021) and laboratory tests. After analysis, curves representing response values versus concentration are plotted for each analyte of interest. As the accuracy of an analytical method is linked to linearity, a non-linear behaviour must be recognized and addressed accordingly. 

Visual inspection of curves is useful but must be accompanied by statistical tests as decision parameters. A commonly used test is the Pearson Correlation Coefficient. However, @sonnergaard2006 suggests that it is an ineffective standalone numeric parameter for accessing linearity. While @vanloco2002, @sanchez2021 and @logue2018 have indicated other metrics for linearity evaluation, these metrics are generally not implemented in most software. Furthermore, using spreadsheet software to individually plot numerous curves is time-consuming. While R (@rprogramming) can plot numerous curve easily, it is hard to implement for a novice analyst.

The R package *lancer* addresses these issues by assisting analysts with useful functions to plot many curves with additional metrics that better describe the curves' characteristics. @fig-visualisation shows that *lancer* also provides an interactive viewer to group, filter and sort the curves, for examination of problematic cases, such as curves generated by saturated signals.

![*lancer*'s interactive visualisation of curves](images/README-TrellisOutput.png){#fig-visualisation}

# Approach

Using response curves in metabolomic/lipidomic studies from @croixmarie2009 and @sands2021 as an example, Supplementary Figure 1 depicts the workflow of *lancer*. The workflow starts with two tables:

*    Curve Batch Annotation, describing the curve(s), such as concentration (x-axis) and response curve batches, if any.
*    Curve Signal Data, containing response values (y-axis) for each sample and curve. 

Using a common column Sample Name, the two tables are merged into one table (Curve Table) via `create_curve_table`.

Next, each curve's summary statistics are calculated via `summarise_curve_table`. Besides the Pearson Correlation Coefficient, an additional statistical test is the Mandel’s Fitting Test ($F_{stats}$ in @eq-mandel-test) as described by @andrade2013. The $F$ test can give evidence that a quadratic model fits better than a linear model, indicating a non-linear curve.

$$
\begin{aligned}
&F_{stats} = \frac{(n-2) \ \mathrm S_{lin}^2 \ - \ (n-3) \ \mathrm S_{quad}^2}{\mathrm S_{quad}^2} \sim \ F(1,n-3)
\\
\\
&\text{where}
\\
&\mathrm S_{lin}^2 = \frac{1}{n-2} \sum_{i=1}^{n} ( y_{i,lin} - y_{i,true})^2 
\\
&\mathrm S_{quad}^2 = \frac{1}{n-3} \sum_{i=1}^{n} ( y_{i,quad} - y_{i,true})^2
\\ 
&y_{i,lin} \ \text{is the linear model predicted y-axis value.}
\\ 
&y_{i,quad} \ \text{is the quadratic model predicted y-axis value.}
\\ 
&y_{i,true} \ \text{is the true y-axis value.}
\\ 
&n \ \text{is the number of data points.}
\end{aligned}
$$ {#eq-mandel-test} Another statistical test is Percent Residual Accuracy ($\%RA$ in @eq-pra) from @logue2018. Ranging from $-\infty$ to $100$, according to which a perfectly linear curve gives a $\%RA$ value of $100$.

$$
\begin{aligned}
&\%RA = \frac{100\%}{n} \sum_{i=1}^{n}\left(1 - \bigg| \frac{x_{i,true}-x_{i,lin}}{x_{i,true}} \bigg|\right)
\\
\\
&\text{where}
\\
&x_{i,true} \ \text{is the true x-axis value.}
\\ 
&x_{i,lin} \ \text{is the linear model predicted x-axis value.}
\\ 
&n \ \text{is the number of data points.}
\end{aligned}
$$ {#eq-pra}

The software also calculates the concavity of the fitted quadratic model, to identify if the curve is dominantly non-linear at high (concavity $<0$) or low (concavity $>0$) concentrations.

Supplementary Figure 2 gives the summary statistics of three simulated curves as examples, where one curve is linear and two non-linear curves with a plateau at high and low concentrations, denoted as saturation and noise regime curve respectively as defined by @galitzine2018. The corresponding Pearson Correlation Coefficient values (`r_corr`) are $\ge0.9$ ($0.99$, $0.95$ and $0.98$ respectively) even for the non-linear curves. However, non-linear curves are detected by much lower Mandel’s Fitting Test $p$ values (`mandel_p_val`) ($1.66 * 10^{-4}$ and $2.56 * 10^{-3}$ respectively vs $0.38$ for the linear curve) and Percent Residual Accuracy values (`pra_linear`) ($62.30$ and $74.69$ respectively vs $94.32$ for the linear curve).

After calculating the summary statistics for each curve, *lancer* uses the function `evaluate_linearity` to group the curves according to the workflows proposed in Supplementary Figure 3. Workflow 1 uses the Pearson Correlation Coefficient and Percent Residual Accuracy to determine if the curve is linear or not, labelled as Good or Poor Linearity respectively. Workflow 2 goes one step further, using Mandel’s Fitting Test and the fitted quadratic model’s concavity to label a non-linear curve as Saturation or Noise Regime, if it plateaus at high or low concentrations respectively. Non-linear curves that do not follow these trends are then labelled as Poor Linearity.

```{r Load Simulated Data Results}
#| echo: false
saturation_regime_curve_summary <-
  readRDS(file = here::here(
    "Quarto_Simulation",
    "saturation_regime_curve_summary.rds")
)

noise_regime_curve_summary <-
  readRDS(file = here::here(
    "Quarto_Simulation",
    "noise_regime_curve_summary.rds")
)

linear_curve_summary <-
  readRDS(file = here::here(
    "Quarto_Simulation",
    "linear_curve_summary.rds")
)
```

```{r Combine Simulated Data Results}
#| echo: false
saturation_regime_curve_summary <- saturation_regime_curve_summary |> 
  dplyr::mutate(curve_group = "Saturation Regime")

noise_regime_curve_summary <- noise_regime_curve_summary |> 
  dplyr::mutate(curve_group = "Noise Regime")

linear_curve_summary <- linear_curve_summary |> 
  dplyr::mutate(curve_group = "Good Linearity")

combined_curve_summary <-
  dplyr::bind_rows(
    saturation_regime_curve_summary,
    noise_regime_curve_summary,
    linear_curve_summary
  ) 
```

```{r Data Wrangling for Simulation Results}
#| echo: false
combined_curve_summary <- 
  combined_curve_summary |> 
  dplyr::mutate(
    curve_group = factor(.data$curve_group,
                         levels = c("Good Linearity",
                                    "Saturation Regime",
                                    "Noise Regime")),
    pearson_group = dplyr::case_when(
      .data$r_corr >= 0.8 ~ "more than or\nequal to 0.8",
      .data$r_corr < 0.8 ~ "less than 0.8",
    ),
    wf2_group = factor(.data$wf2_group,
                       levels = c("Good Linearity",
                                  "Saturation Regime",
                                  "Noise Regime",
                                  "Poor Linearity"))
  ) |> 
  labelled::set_variable_labels(
    ID = "Unique Curve Identifier",
    curve_group = "Simulated Curve Group",
    wf1_group = "Workflow 1 Grouping",
    wf2_group = "Workflow 2 Grouping",
    pearson_group = "Pearson Correlation\nCoefficient Grouping",
    r_corr = "Pearson Correlation\nCoefficient",
    pra_linear = "Percent Residual\nAccuracy",
    mandel_p_val = "Mandel's Test p Value",
    concavity = "Concavity Of Fitted Quadratic Model",
    r2_linear = "Coefficient Of Determination",
    r2_adj_linear = "Adjusted Coefficient Of Determination",
    mandel_stats = "Test statistics from Mandel's Test"
  )

```

```{r Simulation Results Table}
#| echo: false
#| output: false
simulation_results <- combined_curve_summary |> 
  dplyr::select(c("curve_group", "wf2_group", 
                  "pearson_group"
                  # "r_corr", "pra_linear"
                  )
                ) |> 
  dplyr::relocate(c("pearson_group")) |> 
  gtsummary::tbl_summary(
    by = "curve_group",
    statistic = list(
      pearson_group ~ "{n}/{N} ({p}%)",
      wf2_group ~ "{n}/{N} ({p}%)"
    ),
    digits = list(
      wf2_group ~ c(0, 0, 1),
      pearson_group ~ c(0, 0, 1)
      #r_corr ~ c(2),
      #pra_linear ~ c(0)
      )
  ) |> 
  gtsummary::modify_header(
    gtsummary::all_stat_cols() ~ "**{level}**\nN = {n}"
    ) |> 
  gtsummary::modify_spanning_header(
    gtsummary::all_stat_cols() ~ "**Simulated Curve Type**"
    )
```

A benchmark workflow using only Pearson Correlation Coefficient value of $0.8$ is compared with Workflow 2 on simulated data sets of `r nrow(linear_curve_summary)` linear curves (labelled as Linear), non-linear curves that plateau at high and low concentrations (labelled as Saturation and Noise Regime respectively). Supplementary Figure 4 shows that Workflow 2 better identifies the saturation and noise regime curves than the benchmark workflow. While Workflow 2 correctly classifies a lower number of linear curves than the benchmark workflow, its percentage of correctly classified linear curves, `r inline_text(simulation_results, variable = wf2_group, level = "Good Linearity", column = "Good Linearity")`, is high. See <https://lancer-simulation.netlify.app> for report details. While the threshold values of Pearson Correlation Coefficient and Percent Residual Accuracy are based on the interpretation of @y.h.chan2003 and @logue2018, they remain subjective and arbitrary. Nevertheless, *lancer* allows optimization of these threshold values according to the analyst’s preference.

Although *lancer* can export the results in Excel or pdf, an interactive interface can generate a better overview. @fig-visualisation shows a HTML folder, exported by *lancer*. Clicking on the `index.html` file inside the folder opens an interactive plot that can group, filter and sort curves. This allows room for exploratory data analysis, such as identifying curves with linearity issues or understanding the consequence of changing the Pearson Correlation Coefficient threshold to another value. Such information is hard to achieve with static plots alone. An interactive viewer example created by *lancer* can be found at <https://lancer-interactive-example.netlify.app>

# Conclusion

Linearity is one of the most important parameter of an analytical method to be evaluated. Our R package, *lancer*, can access linearity efficiently using functions that quickly plot and report curve summary statistics, which better describe the shape of the curve. It also provides an interactive plot for exploratory data analysis. *lancer* is available on GitHub <https://github.com/SLINGhub/lancer> while the documentation and tutorials can be accessed from <https://slinghub.github.io/lancer>.

# Acknowledgements

These should be included at the end of the text and not in footnotes. Please ensure you acknowledge all sources of funding, see funding section below.

Details of all funding sources for the work in question should be given in a separate section entitled 'Funding'. This should appear before the 'Acknowledgements' section.

# Funding

The following rules should be followed:

-   The sentence should begin: 'This work was supported by ...' -
-   The full official funding agency name should be given, i.e. 'National Institutes of Health', not 'NIH' (full RIN-approved list of UK funding agencies)
-   Grant numbers should be given in brackets as follows: '\[grant number xxxx\]'
-   Multiple grant numbers should be separated by a comma as follows: '\[grant numbers xxxx, yyyy\]'
-   Agencies should be separated by a semi-colon (plus 'and' before the last funding agency)
-   Where individuals need to be specified for certain sources of funding the following text should be added after the relevant agency or grant number 'to \[author initials\]'.

An example is given here: 'This work was supported by the National Institutes of Health \[AA123456 to C.S., BB765432 to M.H.\]; and the Alcohol & Education Research Council \[hfygr667789\].'

Oxford Journals will deposit all NIH-funded articles in PubMed Central. See Depositing articles in repositories -- information for authors for details. Authors must ensure that manuscripts are clearly indicated as NIH-funded using the guidelines above.

# References
